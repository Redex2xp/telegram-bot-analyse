# Telegram-бот для аналитики по видео

Этот проект представляет собой Telegram-бота, который отвечает на вопросы на естественном языке (на русском) для получения статистических данных о видео. Бот использует LLM для преобразования текстовых запросов в SQL-запросы к базе данных PostgreSQL.

## Архитектура

Проект состоит из нескольких ключевых компонентов:

1.  **База данных PostgreSQL**: Хранит статистику по видео и почасовые снапшоты. Запускается в Docker-контейнере.
2.  **Скрипт загрузки данных (`load_data.py`)**: Асинхронный скрипт для парсинга `videos.json` и загрузки данных в PostgreSQL.
3.  **Telegram-бот (`bot.py`)**: Основное приложение на `aiogram`, которое обрабатывает сообщения пользователя.
4.  **Модуль LLM (`llm.py`)**: Отвечает за взаимодействие с API, совместимым с OpenAI. Он формирует промпт, включающий схему БД и примеры, и отправляет его для генерации SQL-запроса.
5.  **Модуль БД (`db.py`)**: Содержит функции для асинхронного подключения к базе данных и выполнения SQL-запросов.

Весь стек полностью асинхронный, что обеспечивает высокую производительность.

## Подход к преобразованию текста в SQL

Основная задача — преобразование запроса на естественном языке в SQL — решается с помощью модели `openai/gpt-4o`. Ключевым элементом является **промпт**, который подается модели.

**Структура промпта (`llm.py`):**

1.  **Роль**: Модели задается роль AI-ассистента, специализирующегося на генерации SQL для PostgreSQL.
2.  **Задача**: Четко указывается, что модель должна вернуть *только* SQL-запрос.
3.  **Схема данных**: В промпт динамически подставляется содержимое файла `sql/init.sql`. Это позволяет модели "видеть" структуру таблиц, типы полей и связи.
4.  **Правила и примеры**: Промпт содержит несколько примеров "вопрос-ответ" (SQL), которые демонстрируют, как обрабатывать разные типы запросов (подсчет, даты, приросты, уникальные значения). Это значительно улучшает точность генерируемых запросов.
5.  **Запрос пользователя**: В конец промпта подставляется фактический текст от пользователя.

Такой подход позволяет модели генерировать корректные SQL-запросы для широкого круга вопросов, не требуя хранения контекста диалога.

## Инструкции по запуску

### Предварительные требования

*   [Docker](https://www.docker.com/get-started) и Docker Compose
*   [Python 3.10+](https://www.python.org/downloads/)
*   Наличие файла `videos.json` в корневой директории проекта.

### Шаг 1: Клонирование репозитория

```bash
git clone https://github.com/Redex2xp/telegram-bot-analyse
cd telegram-bot-analyse
```

### Шаг 2: Настройка переменных окружения

Создайте файл `.env` в корне проекта и заполните его вашими данными:

```env
# Токен вашего Telegram-бота от @BotFather
TELEGRAM_BOT_TOKEN=ВАШ_ТЕЛЕГРАМ_ТОКЕН

# API-ключ для LLM API
AGENTPLATFORM_KEY=ВАШ_КЛЮЧ_API

# Настройки для подключения к PostgreSQL (оставьте по умолчанию для Docker)
DB_HOST=localhost
DB_PORT=5432
DB_USER=postgres
DB_PASSWORD=postgres
DB_NAME=videos_db
```

### Шаг 3: Запуск базы данных

Откройте терминал в корневой директории проекта и выполните команду:

```bash
docker-compose up -d
```
Эта команда запустит контейнер с PostgreSQL в фоновом режиме.

### Шаг 4: Установка зависимостей и загрузка данных

1.  Создайте и активируйте виртуальное окружение:
    ```bash
    python -m venv venv
    # Для Windows
    .\venv\Scripts\activate
    # Для macOS/Linux
    source venv/bin/activate
    ```

2.  Установите необходимые пакеты:
    ```bash
    pip install -r requirements.txt
    ```

3.  Запустите скрипт для создания таблиц и загрузки данных:
    ```bash
    python load_data.py
    ```
    Дождитесь сообщения об успешной загрузке данных.

### Шаг 5: Запуск бота

Теперь, когда база данных запущена и наполнена, а зависимости установлены, можно запустить бота:

```bash
python bot.py
```

После этого ваш бот будет доступен в Telegram и готов к обработке запросов.